{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraper for *everynoise.com*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from https://github.com/aweitz/EveryNoise/blob/master/scrapGenres.ipynb\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"http://everynoise.com/everyschool.cgi?scope=US\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper for *everyschool*\n",
    "\n",
    "Goes to the website and loops through all the schools that are in the USA. Gets the top genres of each school. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link here and read into Python, or just an html link as markdown.\n",
    "# ?root=The%20University%20of%20Texas%20at%20Austin&\n",
    "import re\n",
    "norm = re.compile('[+»&\\s-]')\n",
    "soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "allSchools = soup.find_all(\"tr\", \"datarow\")\n",
    "## Cycle through genres and go to that genres page\n",
    "schools = schools[:-1]\n",
    "# popular_genres = []\n",
    "# playlists = []\n",
    "# schCnt = 0\n",
    "for schoolRow in allSchools[629:]:\n",
    "    print(\"Pulling school #\" + str(schCnt), end = '\\t')\n",
    "    sys.stdout.flush()\n",
    "    school = schoolRow.text.split('USA')[1].strip()\n",
    "    print(school)\n",
    "    schools.append(school)\n",
    "    schoolPage = \"http://everynoise.com/everyschool.cgi?root=\" + school.replace(' ','%20') + \"&scope=US\"\n",
    "    ## Pull artists from genre page\n",
    "    r2 = requests.get(schoolPage)\n",
    "    soup2 = BeautifulSoup(r2.text,\"html.parser\")\n",
    "    schools_genre_div = soup2.find_all(\"div\",\"note\")\n",
    "    inner = soup2.find_all(\"div\",\"note\")\n",
    "    for d in inner:\n",
    "        genres = d.text.split('\\n')[1:-1]\n",
    "        genres = [re.sub(norm,'',g) for g in genres]\n",
    "    popular_genres.append(genres)\n",
    "    spotify = soup2.find(\"iframe\")\n",
    "    playlists.append(spotify['src'])\n",
    "    schCnt = schCnt+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructs the DataFrame for the USA Universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(schools),len(popular_genres),len(playlists))\n",
    "df = pd.DataFrame({'SCHOOL':schools, 'GENRES':popular_genres, 'PLAYLIST_LINK':playlists})\n",
    "df.to_csv('school_genres.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper for *genremap* \n",
    "Goes to the website and enters each genre link and scraps the html. Grabs the related genres, opposite genres, and uses the font size for each as a  indicator of edge 'weight'. Also gets the Spotify playlist links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"http://everynoise.com/engenremap.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "allGenreDivs = soup.find_all(\"div\", \"genre scanme\")\n",
    "\n",
    "## Cycle through genres and go to that genres page\n",
    "genreListArtist = []\n",
    "genreListOpp = []\n",
    "genreListSim = []\n",
    "genreList = []\n",
    "playlists = []\n",
    "simWeights = []\n",
    "oppWeights = []\n",
    "artistWeights = []\n",
    "genreCnt = 0\n",
    "for genreDiv in allGenreDivs:\n",
    "    print(\"Pulling genre #\" + str(genreCnt))\n",
    "    sys.stdout.flush()\n",
    "    genre = (genreDiv.text)\n",
    "    genre = re.sub(\"[:'+»&\\s-]\", '', genre)    \n",
    "    genreList.append(genre)\n",
    "    genrePage = \"http://everynoise.com/engenremap-\" + genre + \".html\"\n",
    "\n",
    "    ## Pull artists from genre page\n",
    "    r2 = requests.get(genrePage)\n",
    "    soup2 = BeautifulSoup(r2.text,\"html.parser\")\n",
    "    spotify_link = soup2.find_all(\"a\", text = 'playlist')\n",
    "    playlists.append(spotify_link[0]['href'])\n",
    "    allArtistDivs = set(soup2.find_all(\"div\", \"genre scanme\"))\n",
    "    allGenresRelated = set(soup2.find_all(\"div\", \"genre\"))\n",
    "    allGenresRelated = allGenresRelated - allArtistDivs\n",
    "    artistList = []\n",
    "    art_w = []\n",
    "    \n",
    "    for artist in allArtistDivs:\n",
    "        weight = artist['style'].split()[-1].replace('%', '')\n",
    "        artistName = artist.text.strip().replace(\"»\", \"\").replace(' ', '')\n",
    "        if not(artistName.isspace()):   \n",
    "            art_w.append(weight)\n",
    "            artistList.append(artistName) \n",
    "    artistWeights.append(art_w)\n",
    "    genreListArtist.append(artistList)\n",
    "    \n",
    "    simGenres = []\n",
    "    oppGenres = []\n",
    "    weights_sim = []\n",
    "    weights_opp = []\n",
    "    \n",
    "    for other_genre in allGenresRelated:\n",
    "        weight = other_genre['style'].split()[-1].replace('%', '')\n",
    "        if 'nearby' in other_genre['id']:\n",
    "            weights_sim.append(weight)\n",
    "            simGenres.append(other_genre.text.strip().replace(\"»\", \"\").replace(' ', ''))\n",
    "        elif 'mirror' in other_genre['id']:\n",
    "            weights_opp.append(weight)\n",
    "            oppGenres.append(other_genre.text.strip().replace(\"»\", \"\").replace(' ', ''))\n",
    "    genreListSim.append(simGenres)\n",
    "    genreListOpp.append(oppGenres)\n",
    "    simWeights.append(weights_sim)\n",
    "    oppWeights.append(weights_opp)\n",
    "    genreCnt = genreCnt+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructs the Dataframe for All Genres and Converts it to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genreListArtist = []\n",
    "# genreListOpp = []\n",
    "# genreListSim = []\n",
    "# genreList = []\n",
    "# playlists = []\n",
    "df = pd.DataFrame({\"GENRE\":genreList, \n",
    "                   \"SIM_GENRES\":genreListSim,\n",
    "                   \"SIM_WEIGHTS\":simWeights,\n",
    "                   \"OPP_GENRES\":genreListOpp,\n",
    "                   \"OPP_WEIGHTS\":oppWeights,\n",
    "                   \"REL_ARTISTS\":genreListArtist, \n",
    "                   \"ARTIST_WEIGHTS\":artistWeights,\n",
    "                   \"SPOTIFY_URL\":playlists})\n",
    "df.to_csv('all_genres.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
